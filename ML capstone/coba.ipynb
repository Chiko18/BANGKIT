{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\argo\\\\Downloads\\\\Plastic detection.v1i.multiclass\\\\train\\\\_classes.csv\", delimiter=\",\")\n",
    "dict_plastic = {}\n",
    "\n",
    "for number, name in enumerate(df.columns):\n",
    "    if name == 'filename':continue              # skip 1st column\n",
    "    dict_plastic[number-1] = name.strip()\n",
    "dict_plastic = {key: dict_plastic[key] for key in dict_plastic if key != 'Unlabeled'}\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(path, label, image_size=(224,224), return_label=False):\n",
    "    labels = pd.read_csv(label)\n",
    "    labels = labels.sort_values('filename')\n",
    "    labels = labels.loc[:, labels.columns != 'filename']\n",
    "    labels = np.array(labels.idxmax(axis=1).str.strip().astype(\n",
    "            'category').cat.codes).reshape(-1,1)\n",
    "    \n",
    "    if return_label:\n",
    "        return labels\n",
    "    images = tf.keras.utils.image_dataset_from_directory(path, shuffle=False, batch_size=None, label_mode=None, image_size=image_size)\n",
    "    labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8110 files belonging to 1 classes.\n",
      "Found 869 files belonging to 1 classes.\n",
      "Found 435 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "path_train = \"C:\\\\Users\\\\argo\\\\Downloads\\\\Plastic detection.v1i.multiclass\\\\train\\\\\"\n",
    "path_valid = \"C:\\\\Users\\\\argo\\\\Downloads\\\\Plastic detection.v1i.multiclass\\\\valid\\\\\"\n",
    "path_test = \"C:\\\\Users\\\\argo\\\\Downloads\\\\Plastic detection.v1i.multiclass\\\\test\\\\\"\n",
    "train_dataset = loadImage(path_train, path_train+\"_classes.csv\", image_size=(img_size,img_size))\n",
    "valid_dataset = loadImage(path_valid, path_valid+\"_classes.csv\", image_size=(img_size,img_size))\n",
    "test_dataset = loadImage(path_test, path_test+\"_classes.csv\", image_size=(img_size,img_size))\n",
    "test_labels = loadImage(path_test, path_test+\"_classes.csv\", return_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_dataset.cache('train1').shuffle(500).batch(32)\n",
    "valid = valid_dataset.cache().batch(32)\n",
    "test = test_dataset.cache().batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=tf.keras.applications.convnext.ConvNeXtBase(\n",
    "        model_name='convnext_base',\n",
    "        include_top=False,\n",
    "        include_preprocessing=True,\n",
    "        input_shape=(img_size,img_size,3),\n",
    "        pooling='max',\n",
    "    \n",
    ")\n",
    "model2.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convnext_base (Functional)  (None, 1024)              87566464  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 23)                23575     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87590039 (334.13 MB)\n",
      "Trainable params: 23575 (92.09 KB)\n",
      "Non-trainable params: 87566464 (334.04 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= tf.keras.models.Sequential([\n",
    "    model2,\n",
    "    tf.keras.layers.Dense(len(dict_plastic),\"softmax\")\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.build([None,224,224,3])\n",
    "model.summary(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/254 [..............................] - ETA: 3:25:21 - loss: 2.3911 - accuracy: 0.3281"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    epochs=10\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
